{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Australia Weather Forecast\n",
    "\n",
    "The Dataset contains daily weather observations from numerous Australian weather stations.\n",
    "\n",
    "- **Goal:** predict the weather next day \n",
    "- **Metric:** Accuracy\n",
    "- **Libraries:** numpy, pandas, sklearn, matplotlib\n",
    "- **Hardware:** CPU only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing libraries\n",
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Data preprocessing\n",
    "from sklearn.preprocessing import Imputer\n",
    "\n",
    "# Machine learning\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Hiding unecessary warnings to make it more readable\n",
    "import warnings \n",
    "warnings.filterwarnings('ignore')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"weather_austria.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Location</th>\n",
       "      <th>MinTemp</th>\n",
       "      <th>MaxTemp</th>\n",
       "      <th>Rainfall</th>\n",
       "      <th>Evaporation</th>\n",
       "      <th>Sunshine</th>\n",
       "      <th>WindGustDir</th>\n",
       "      <th>WindGustSpeed</th>\n",
       "      <th>WindDir9am</th>\n",
       "      <th>...</th>\n",
       "      <th>Humidity3pm</th>\n",
       "      <th>Pressure9am</th>\n",
       "      <th>Pressure3pm</th>\n",
       "      <th>Cloud9am</th>\n",
       "      <th>Cloud3pm</th>\n",
       "      <th>Temp9am</th>\n",
       "      <th>Temp3pm</th>\n",
       "      <th>RainToday</th>\n",
       "      <th>RISK_MM</th>\n",
       "      <th>RainTomorrow</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2008-12-01</td>\n",
       "      <td>Albury</td>\n",
       "      <td>13.4</td>\n",
       "      <td>22.9</td>\n",
       "      <td>0.6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>W</td>\n",
       "      <td>44.0</td>\n",
       "      <td>W</td>\n",
       "      <td>...</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1007.7</td>\n",
       "      <td>1007.1</td>\n",
       "      <td>8.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>16.9</td>\n",
       "      <td>21.8</td>\n",
       "      <td>No</td>\n",
       "      <td>0.0</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2008-12-02</td>\n",
       "      <td>Albury</td>\n",
       "      <td>7.4</td>\n",
       "      <td>25.1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>WNW</td>\n",
       "      <td>44.0</td>\n",
       "      <td>NNW</td>\n",
       "      <td>...</td>\n",
       "      <td>25.0</td>\n",
       "      <td>1010.6</td>\n",
       "      <td>1007.8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>17.2</td>\n",
       "      <td>24.3</td>\n",
       "      <td>No</td>\n",
       "      <td>0.0</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2008-12-03</td>\n",
       "      <td>Albury</td>\n",
       "      <td>12.9</td>\n",
       "      <td>25.7</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>WSW</td>\n",
       "      <td>46.0</td>\n",
       "      <td>W</td>\n",
       "      <td>...</td>\n",
       "      <td>30.0</td>\n",
       "      <td>1007.6</td>\n",
       "      <td>1008.7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>23.2</td>\n",
       "      <td>No</td>\n",
       "      <td>0.0</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2008-12-04</td>\n",
       "      <td>Albury</td>\n",
       "      <td>9.2</td>\n",
       "      <td>28.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NE</td>\n",
       "      <td>24.0</td>\n",
       "      <td>SE</td>\n",
       "      <td>...</td>\n",
       "      <td>16.0</td>\n",
       "      <td>1017.6</td>\n",
       "      <td>1012.8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>18.1</td>\n",
       "      <td>26.5</td>\n",
       "      <td>No</td>\n",
       "      <td>1.0</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2008-12-05</td>\n",
       "      <td>Albury</td>\n",
       "      <td>17.5</td>\n",
       "      <td>32.3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>W</td>\n",
       "      <td>41.0</td>\n",
       "      <td>ENE</td>\n",
       "      <td>...</td>\n",
       "      <td>33.0</td>\n",
       "      <td>1010.8</td>\n",
       "      <td>1006.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>17.8</td>\n",
       "      <td>29.7</td>\n",
       "      <td>No</td>\n",
       "      <td>0.2</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         Date Location  MinTemp  MaxTemp  Rainfall  Evaporation  Sunshine  \\\n",
       "0  2008-12-01   Albury     13.4     22.9       0.6          NaN       NaN   \n",
       "1  2008-12-02   Albury      7.4     25.1       0.0          NaN       NaN   \n",
       "2  2008-12-03   Albury     12.9     25.7       0.0          NaN       NaN   \n",
       "3  2008-12-04   Albury      9.2     28.0       0.0          NaN       NaN   \n",
       "4  2008-12-05   Albury     17.5     32.3       1.0          NaN       NaN   \n",
       "\n",
       "  WindGustDir  WindGustSpeed WindDir9am  ... Humidity3pm  Pressure9am  \\\n",
       "0           W           44.0          W  ...        22.0       1007.7   \n",
       "1         WNW           44.0        NNW  ...        25.0       1010.6   \n",
       "2         WSW           46.0          W  ...        30.0       1007.6   \n",
       "3          NE           24.0         SE  ...        16.0       1017.6   \n",
       "4           W           41.0        ENE  ...        33.0       1010.8   \n",
       "\n",
       "   Pressure3pm  Cloud9am  Cloud3pm  Temp9am  Temp3pm  RainToday  RISK_MM  \\\n",
       "0       1007.1       8.0       NaN     16.9     21.8         No      0.0   \n",
       "1       1007.8       NaN       NaN     17.2     24.3         No      0.0   \n",
       "2       1008.7       NaN       2.0     21.0     23.2         No      0.0   \n",
       "3       1012.8       NaN       NaN     18.1     26.5         No      1.0   \n",
       "4       1006.0       7.0       8.0     17.8     29.7         No      0.2   \n",
       "\n",
       "   RainTomorrow  \n",
       "0            No  \n",
       "1            No  \n",
       "2            No  \n",
       "3            No  \n",
       "4            No  \n",
       "\n",
       "[5 rows x 24 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 145460 entries, 0 to 145459\n",
      "Data columns (total 24 columns):\n",
      "Date             145460 non-null object\n",
      "Location         145460 non-null object\n",
      "MinTemp          143975 non-null float64\n",
      "MaxTemp          144199 non-null float64\n",
      "Rainfall         142199 non-null float64\n",
      "Evaporation      82670 non-null float64\n",
      "Sunshine         75625 non-null float64\n",
      "WindGustDir      135134 non-null object\n",
      "WindGustSpeed    135197 non-null float64\n",
      "WindDir9am       134894 non-null object\n",
      "WindDir3pm       141232 non-null object\n",
      "WindSpeed9am     143693 non-null float64\n",
      "WindSpeed3pm     142398 non-null float64\n",
      "Humidity9am      142806 non-null float64\n",
      "Humidity3pm      140953 non-null float64\n",
      "Pressure9am      130395 non-null float64\n",
      "Pressure3pm      130432 non-null float64\n",
      "Cloud9am         89572 non-null float64\n",
      "Cloud3pm         86102 non-null float64\n",
      "Temp9am          143693 non-null float64\n",
      "Temp3pm          141851 non-null float64\n",
      "RainToday        142199 non-null object\n",
      "RISK_MM          142193 non-null float64\n",
      "RainTomorrow     142193 non-null object\n",
      "dtypes: float64(17), object(7)\n",
      "memory usage: 26.6+ MB\n"
     ]
    }
   ],
   "source": [
    "df.set_index(\"Date\")\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               Total    Percent\n",
      "Sunshine       69835  48.009762\n",
      "Evaporation    62790  43.166506\n",
      "Cloud3pm       59358  40.807095\n",
      "Cloud9am       55888  38.421559\n",
      "Pressure9am    15065  10.356799\n",
      "Pressure3pm    15028  10.331363\n",
      "WindDir9am     10566   7.263853\n",
      "WindGustDir    10326   7.098859\n",
      "WindGustSpeed  10263   7.055548\n",
      "Humidity3pm     4507   3.098446\n",
      "WindDir3pm      4228   2.906641\n",
      "Temp3pm         3609   2.481094\n",
      "RISK_MM         3267   2.245978\n",
      "RainTomorrow    3267   2.245978\n",
      "Rainfall        3261   2.241853\n",
      "RainToday       3261   2.241853\n",
      "WindSpeed3pm    3062   2.105046\n",
      "Humidity9am     2654   1.824557\n",
      "WindSpeed9am    1767   1.214767\n",
      "Temp9am         1767   1.214767\n",
      "MinTemp         1485   1.020899\n",
      "MaxTemp         1261   0.866905\n",
      "Location           0   0.000000\n",
      "Date               0   0.000000\n"
     ]
    }
   ],
   "source": [
    "# Exploring missing values\n",
    "def missing_data_overview(num_of_rows=50):\n",
    "    total = df.isnull().sum().sort_values(ascending=False)\n",
    "    percent = (df.isnull().sum()/df.isnull().count() * 100).sort_values(ascending=False)\n",
    "    missing_data = pd.concat([total, percent], axis=1, keys=['Total', 'Percent'])\n",
    "    print(missing_data.head(num_of_rows))\n",
    "\n",
    "missing_data_overview()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Selection/Exploration\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original number of features: 63\n",
      "Reduced number of features: 4\n",
      "K best features are: Index(['Humidity3pm', 'Cloud9am', 'Cloud3pm', 'RainToday'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import f_classif\n",
    "\n",
    "# Copy dataframe for exploration\n",
    "df_tmp = df.copy()\n",
    "# Transforming yes/no values into numerical values\n",
    "df_tmp['RainToday'].replace({'No': 0, 'Yes': 1},inplace = True)\n",
    "df_tmp['RainTomorrow'].replace({'No': 0, 'Yes': 1},inplace = True)\n",
    "\n",
    "# One-hot encode data\n",
    "df_tmp = pd.get_dummies(df_tmp, columns=['WindGustDir','WindDir9am', 'WindDir3pm'])\n",
    "\n",
    "df_tmp = df_tmp.dropna(how='any')\n",
    "\n",
    "\n",
    "y = df_tmp[['RainTomorrow']]\n",
    "X = df_tmp.drop(['Date', 'Location', 'Sunshine', 'Evaporation', 'RainTomorrow', 'RISK_MM'], axis=1)\n",
    "\n",
    "# Create an SelectKBest object to select features with two best ANOVA F-Values\n",
    "fvalue_selector = SelectKBest(f_classif, k=4)\n",
    "\n",
    "# Apply the SelectKBest object to the features and target\n",
    "X_kbest = fvalue_selector.fit_transform(X, y)\n",
    "\n",
    "# Show results\n",
    "print('Original number of features:', X.shape[1])\n",
    "print('Reduced number of features:', X_kbest.shape[1])\n",
    "\n",
    "# Boolean array of best features - True:= within k best features\n",
    "mask = fvalue_selector.get_support()\n",
    "\n",
    "# Storing column names of k best features\n",
    "new_features = X.columns[mask]\n",
    "print(\"K best features are:\", new_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Humidity3pm* and *RainToday* are the best features here since Cloud9am and Cloud3pm are missing most of its data in our original dataframe."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Engineering/Transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# transforming yes/no values into numerical values\n",
    "df['RainToday'].replace({'No': 0, 'Yes': 1},inplace = True)\n",
    "df['RainTomorrow'].replace({'No': 0, 'Yes': 1},inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filling missing values of the \"Humidity3pm\" column\n",
    "mean_imputer = Imputer(missing_values='NaN', strategy='mean', axis=0)\n",
    "mean_imputer.fit(df['Humidity3pm'].values.reshape(-1, 1))\n",
    "df['Humidity3pm'] = mean_imputer.transform(df['Humidity3pm'].values.reshape(-1, 1))\n",
    "# Droping rows with missing values in the \"Rainfall\" column\n",
    "df = df[pd.notnull(df['RainTomorrow'])]\n",
    "df = df[pd.notnull(df['RainToday'])]\n",
    "df = pd.get_dummies(df, columns=['WindGustDir','WindDir9am', 'WindDir3pm'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'missing_data_overview' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-c9b7f1b2e910>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmissing_data_overview\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'missing_data_overview' is not defined"
     ]
    }
   ],
   "source": [
    "print(missing_data_overview(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Humidity3pm</th>\n",
       "      <th>RainToday</th>\n",
       "      <th>RainToday</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>22.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>25.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>30.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>16.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>33.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Humidity3pm  RainToday  RainToday\n",
       "0         22.0        0.0        0.0\n",
       "1         25.0        0.0        0.0\n",
       "2         30.0        0.0        0.0\n",
       "3         16.0        0.0        0.0\n",
       "4         33.0        0.0        0.0"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# selecting important features that are most valuable for our prediction\n",
    "df = df[['Humidity3pm','Rainfall','RainToday','RainTomorrow', 'RainToday']]\n",
    "X = df[['Humidity3pm', 'RainToday']] # let's use only one feature Humidity3pm\n",
    "y = df[['RainTomorrow']]\n",
    "\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Model Selection\n",
    "\n",
    "#### Comapring different models:\n",
    "- Decision Trees\n",
    "- Random Forest\n",
    "- Support Vector machine\n",
    "- Adaboost\n",
    "- Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# spliting the data into a training and test set\n",
    "X_train,X_test,y_train,y_test = train_test_split(X,y,test_size=0.25)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Decision Tree Classifier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trainings Time: 0.034882545471191406\n",
      "Prediction Time: 0.002991914749145508\n",
      "---------------------------------------\n",
      "Decision Tree accuracy: 0.8298434525669801\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "dt_clf = DecisionTreeClassifier(criterion='gini', random_state=0)\n",
    "\n",
    "t0=time.time()\n",
    "dt_model = dt_clf.fit(X_train, y_train)\n",
    "print(\"Trainings Time:\", time.time()-t0)\n",
    "\n",
    "t0=time.time()\n",
    "y_pred = dt_model.predict(X_test)\n",
    "print(\"Prediction Time:\", time.time()-t0)\n",
    "\n",
    "dt_acc = accuracy_score(y_test,y_pred)\n",
    "print(\"---------------------------------------\")\n",
    "print(\"Decision Tree accuracy:\", dt_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trainings Time: 0.11668825149536133\n",
      "Prediction Time: 0.10491585731506348\n",
      "---------------------------------------\n",
      "Random Forest accuracy: 0.829587748955877\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "rf_clf = RandomForestClassifier(criterion='entropy', random_state=0, n_jobs=-1)\n",
    "\n",
    "t0=time.time()\n",
    "rf_model = rf_clf.fit(X_train, y_train)\n",
    "print(\"Trainings Time:\", time.time()-t0)\n",
    "\n",
    "t0=time.time()\n",
    "y_pred = rf_model.predict(X_test)\n",
    "print(\"Prediction Time:\", time.time()-t0)\n",
    "\n",
    "rf_acc = accuracy_score(y_pred, y_test)\n",
    "print(\"---------------------------------------\")\n",
    "print(\"Random Forest accuracy:\", rf_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Support Vector Machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trainings Time: 4.12811279296875\n",
      "Prediction Time: 0.015109777450561523\n",
      "---------------------------------------\n",
      "Support Vector Machine accuracy: 0.22280307980793818\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_std = scaler.fit_transform(X)\n",
    "svc_clf = LinearSVC(C=1.0)\n",
    "\n",
    "t0=time.time()\n",
    "svc_model = svc_clf.fit(X_std, y)\n",
    "print(\"Trainings Time:\", time.time()-t0)\n",
    "\n",
    "t0=time.time()\n",
    "y_pred = svc_model.predict(X_test)\n",
    "print(\"Prediction Time:\", time.time()-t0)\n",
    "\n",
    "svc_acc = accuracy_score(y_pred, y_test)\n",
    "print(\"---------------------------------------\")\n",
    "print(\"Support Vector Machine accuracy:\", svc_acc)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adaboos Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trainings Time: 2.0581631660461426\n",
      "Prediction Time: 0.11470794677734375\n",
      "---------------------------------------\n",
      "Adaboost accuracy: 0.8312924396965651\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "\n",
    "ab_clf = AdaBoostClassifier(n_estimators=50,\n",
    "                         learning_rate=1,\n",
    "                         random_state=0)\n",
    "\n",
    "t0=time.time()\n",
    "ab_model = ab_clf.fit(X, y)\n",
    "print(\"Trainings Time:\", time.time()-t0)\n",
    "\n",
    "t0=time.time()\n",
    "y_pred = ab_model.predict(X_test)\n",
    "print(\"Prediction Time:\", time.time()-t0)\n",
    "\n",
    "ab_acc = accuracy_score(y_pred, y_test)\n",
    "print(\"---------------------------------------\")\n",
    "print(\"Adaboost accuracy:\", ab_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trainings Time: 0.1550908088684082\n",
      "Prediction Time: 0.000997304916381836\n",
      "---------------------------------------\n",
      "Logistic Regression accuracy: 0.22280307980793818\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_std = scaler.fit_transform(X)\n",
    "\n",
    "lr_clf = LogisticRegression(random_state=0)\n",
    "\n",
    "t0=time.time()\n",
    "lr_model = lr_clf.fit(X_std, y)\n",
    "print(\"Trainings Time:\", time.time()-t0)\n",
    "\n",
    "t0=time.time()\n",
    "y_pred = lr_model.predict(X_test)\n",
    "print(\"Prediction Time:\", time.time()-t0)\n",
    "\n",
    "lr_acc = accuracy_score(y_pred, y_test)\n",
    "print(\"---------------------------------------\")\n",
    "print(\"Logistic Regression accuracy:\", lr_acc)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusion\n",
    "\n",
    "As we can see, adaboost is outperforming all other models by a significant amount when it comes to the training the model and predictions.\n",
    "\n",
    "Im not enitrely sure why the logisitic regression model is underperforming, so it will need further investigations. \n",
    "Considering the current technical setup, I would pick the adaboost classifier folowed by decision tree classifier. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
